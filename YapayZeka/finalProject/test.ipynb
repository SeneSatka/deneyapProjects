{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_15 (Dense)            (None, 500)               2000      \n",
      "                                                                 \n",
      " leaky_re_lu_8 (LeakyReLU)   (None, 500)               0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 500)               250500    \n",
      "                                                                 \n",
      " leaky_re_lu_9 (LeakyReLU)   (None, 500)               0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 500)               250500    \n",
      "                                                                 \n",
      " leaky_re_lu_10 (LeakyReLU)  (None, 500)               0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 500)               250500    \n",
      "                                                                 \n",
      " leaky_re_lu_11 (LeakyReLU)  (None, 500)               0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 500)               250500    \n",
      "                                                                 \n",
      " leaky_re_lu_12 (LeakyReLU)  (None, 500)               0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 10)                5010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,009,010\n",
      "Trainable params: 1,009,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "132/132 [==============================] - 5s 31ms/step - loss: 1242.3712 - acc: 0.2089 - val_loss: 243.4044 - val_acc: 0.2120\n",
      "Epoch 2/50\n",
      "132/132 [==============================] - 3s 26ms/step - loss: 85.5523 - acc: 0.2417 - val_loss: 134.0638 - val_acc: 0.2037\n",
      "Epoch 3/50\n",
      "132/132 [==============================] - 4s 29ms/step - loss: 46.4970 - acc: 0.2546 - val_loss: 16.1960 - val_acc: 0.2865\n",
      "Epoch 4/50\n",
      "132/132 [==============================] - 3s 25ms/step - loss: 10.6672 - acc: 0.2684 - val_loss: 7.6563 - val_acc: 0.2684\n",
      "Epoch 5/50\n",
      "132/132 [==============================] - 4s 28ms/step - loss: 7.0331 - acc: 0.2857 - val_loss: 5.6048 - val_acc: 0.2643\n",
      "Epoch 6/50\n",
      "132/132 [==============================] - 3s 25ms/step - loss: 5.3050 - acc: 0.2800 - val_loss: 2.3395 - val_acc: 0.3064\n",
      "Epoch 7/50\n",
      "132/132 [==============================] - 3s 26ms/step - loss: 3.0742 - acc: 0.3041 - val_loss: 2.8590 - val_acc: 0.2758\n",
      "Epoch 8/50\n",
      "132/132 [==============================] - 4s 33ms/step - loss: 2.6816 - acc: 0.2886 - val_loss: 2.2813 - val_acc: 0.2922\n",
      "Epoch 9/50\n",
      "132/132 [==============================] - 3s 25ms/step - loss: 1.9592 - acc: 0.2879 - val_loss: 1.9063 - val_acc: 0.2658\n",
      "Epoch 10/50\n",
      "132/132 [==============================] - 3s 24ms/step - loss: 2.2994 - acc: 0.2979 - val_loss: 2.1106 - val_acc: 0.2777\n",
      "Epoch 11/50\n",
      "132/132 [==============================] - 3s 24ms/step - loss: 1.9785 - acc: 0.2829 - val_loss: 1.9403 - val_acc: 0.2819\n",
      "Epoch 12/50\n",
      "132/132 [==============================] - 5s 34ms/step - loss: 1.8877 - acc: 0.3000 - val_loss: 1.8320 - val_acc: 0.2903\n",
      "Epoch 13/50\n",
      "132/132 [==============================] - 4s 30ms/step - loss: 1.8107 - acc: 0.2988 - val_loss: 1.7745 - val_acc: 0.2912\n",
      "Epoch 14/50\n",
      "132/132 [==============================] - 5s 36ms/step - loss: 1.8254 - acc: 0.3015 - val_loss: 1.8321 - val_acc: 0.3179\n",
      "Epoch 15/50\n",
      "132/132 [==============================] - 5s 35ms/step - loss: 1.8115 - acc: 0.3024 - val_loss: 1.7870 - val_acc: 0.2926\n",
      "Epoch 16/50\n",
      "132/132 [==============================] - 4s 33ms/step - loss: 1.8022 - acc: 0.3041 - val_loss: 1.7753 - val_acc: 0.3012\n",
      "Epoch 17/50\n",
      "132/132 [==============================] - 4s 28ms/step - loss: 1.8156 - acc: 0.3041 - val_loss: 1.9259 - val_acc: 0.2960\n",
      "Epoch 18/50\n",
      "132/132 [==============================] - 5s 40ms/step - loss: 1.7752 - acc: 0.3131 - val_loss: 1.8160 - val_acc: 0.3010\n",
      "Epoch 19/50\n",
      "132/132 [==============================] - 4s 29ms/step - loss: 1.7638 - acc: 0.3172 - val_loss: 1.7549 - val_acc: 0.2798\n",
      "Epoch 20/50\n",
      "132/132 [==============================] - 4s 30ms/step - loss: 1.7522 - acc: 0.3129 - val_loss: 1.7595 - val_acc: 0.3010\n",
      "Epoch 21/50\n",
      "132/132 [==============================] - 4s 32ms/step - loss: 1.7552 - acc: 0.3202 - val_loss: 1.8827 - val_acc: 0.2993\n",
      "Epoch 22/50\n",
      "132/132 [==============================] - 4s 28ms/step - loss: 1.7896 - acc: 0.3105 - val_loss: 1.7433 - val_acc: 0.2946\n",
      "Epoch 23/50\n",
      "132/132 [==============================] - 4s 32ms/step - loss: 1.7809 - acc: 0.3131 - val_loss: 1.7208 - val_acc: 0.3067\n",
      "Epoch 24/50\n",
      "132/132 [==============================] - 5s 40ms/step - loss: 1.7481 - acc: 0.3183 - val_loss: 1.7592 - val_acc: 0.2993\n",
      "Epoch 25/50\n",
      "132/132 [==============================] - 5s 39ms/step - loss: 1.7501 - acc: 0.3093 - val_loss: 1.7858 - val_acc: 0.2988\n",
      "Epoch 26/50\n",
      "132/132 [==============================] - 4s 32ms/step - loss: 1.7483 - acc: 0.3136 - val_loss: 1.7323 - val_acc: 0.2948\n",
      "Epoch 27/50\n",
      "132/132 [==============================] - 5s 39ms/step - loss: 1.7228 - acc: 0.3107 - val_loss: 1.7373 - val_acc: 0.3107\n",
      "Epoch 28/50\n",
      "132/132 [==============================] - 4s 29ms/step - loss: 1.7452 - acc: 0.3191 - val_loss: 1.7375 - val_acc: 0.3148\n",
      "Epoch 29/50\n",
      "132/132 [==============================] - 3s 24ms/step - loss: 1.7516 - acc: 0.3122 - val_loss: 1.8300 - val_acc: 0.2931\n",
      "Epoch 30/50\n",
      "132/132 [==============================] - 4s 27ms/step - loss: 1.7558 - acc: 0.3117 - val_loss: 1.7281 - val_acc: 0.3069\n",
      "Epoch 31/50\n",
      "132/132 [==============================] - 4s 30ms/step - loss: 1.7299 - acc: 0.3188 - val_loss: 1.7764 - val_acc: 0.3029\n",
      "Epoch 32/50\n",
      "132/132 [==============================] - 5s 40ms/step - loss: 1.7395 - acc: 0.3150 - val_loss: 1.7350 - val_acc: 0.3195\n",
      "Epoch 33/50\n",
      "132/132 [==============================] - 5s 35ms/step - loss: 1.7295 - acc: 0.3255 - val_loss: 1.7697 - val_acc: 0.3164\n",
      "Epoch 34/50\n",
      "132/132 [==============================] - 4s 33ms/step - loss: 282.7613 - acc: 0.2584 - val_loss: 142.8470 - val_acc: 0.2317\n",
      "Epoch 35/50\n",
      "132/132 [==============================] - 5s 38ms/step - loss: 50.7060 - acc: 0.2229 - val_loss: 3.2940 - val_acc: 0.2389\n",
      "Epoch 36/50\n",
      "132/132 [==============================] - 4s 32ms/step - loss: 6.3851 - acc: 0.2719 - val_loss: 7.5337 - val_acc: 0.2831\n",
      "Epoch 37/50\n",
      "132/132 [==============================] - 5s 35ms/step - loss: 3.0356 - acc: 0.2877 - val_loss: 3.1185 - val_acc: 0.2753\n",
      "Epoch 38/50\n",
      "132/132 [==============================] - 4s 30ms/step - loss: 2.4042 - acc: 0.2903 - val_loss: 2.4983 - val_acc: 0.2857\n",
      "Epoch 39/50\n",
      "132/132 [==============================] - 4s 31ms/step - loss: 2.1049 - acc: 0.2934 - val_loss: 1.8290 - val_acc: 0.2753\n",
      "Epoch 40/50\n",
      "132/132 [==============================] - 5s 35ms/step - loss: 2.1966 - acc: 0.2888 - val_loss: 1.9634 - val_acc: 0.2957\n",
      "Epoch 41/50\n",
      "132/132 [==============================] - 4s 31ms/step - loss: 1.8804 - acc: 0.2953 - val_loss: 1.9583 - val_acc: 0.2643\n",
      "Epoch 42/50\n",
      "132/132 [==============================] - 5s 35ms/step - loss: 1.8910 - acc: 0.2910 - val_loss: 1.8505 - val_acc: 0.2810\n",
      "Epoch 43/50\n",
      "132/132 [==============================] - 4s 33ms/step - loss: 1.8318 - acc: 0.2917 - val_loss: 2.2030 - val_acc: 0.2884\n",
      "Epoch 44/50\n",
      "132/132 [==============================] - 5s 38ms/step - loss: 2.5177 - acc: 0.2965 - val_loss: 2.5437 - val_acc: 0.2884\n",
      "Epoch 45/50\n",
      "132/132 [==============================] - 5s 36ms/step - loss: 2.2540 - acc: 0.3041 - val_loss: 1.9172 - val_acc: 0.2627\n",
      "Epoch 46/50\n",
      "132/132 [==============================] - 4s 28ms/step - loss: 1.8432 - acc: 0.2910 - val_loss: 1.8053 - val_acc: 0.2767\n",
      "Epoch 47/50\n",
      "132/132 [==============================] - 5s 36ms/step - loss: 1.8779 - acc: 0.2919 - val_loss: 1.9186 - val_acc: 0.2781\n",
      "Epoch 48/50\n",
      "132/132 [==============================] - 5s 35ms/step - loss: 1.8669 - acc: 0.3038 - val_loss: 2.1146 - val_acc: 0.2762\n",
      "Epoch 49/50\n",
      "132/132 [==============================] - 3s 23ms/step - loss: 1.9965 - acc: 0.2950 - val_loss: 1.9857 - val_acc: 0.2772\n",
      "Epoch 50/50\n",
      "132/132 [==============================] - 4s 32ms/step - loss: 2.1676 - acc: 0.2874 - val_loss: 1.9135 - val_acc: 0.2696\n",
      "132/132 [==============================] - 1s 6ms/step\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Activation,LeakyReLU\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import preprocessing \n",
    "import pandas as pd\n",
    "\n",
    "ppgn=preprocessing.LabelEncoder()\n",
    "a=pd.read_csv(\"./emission_dataset.csv\",encoding=\"unicode_escape\")\n",
    "dataset=a.copy()\n",
    "\n",
    "dataset[\"country_or_area\"]=ppgn.fit_transform(dataset[\"country_or_area\"])\n",
    "dataset[\"category\"]=ppgn.fit_transform(dataset[\"category\"])\n",
    "X=dataset.drop(\"category\",axis=1)\n",
    "y= to_categorical(dataset[\"category\"])\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.5,random_state=1)\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Dense(units=500,input_dim=3))\n",
    "model.add(LeakyReLU(alpha=0.01))\n",
    "model.add(Dense(units=500))\n",
    "model.add(LeakyReLU(alpha=0.01))\n",
    "model.add(Dense(units=500))\n",
    "model.add(LeakyReLU(alpha=0.01))\n",
    "model.add(Dense(units=500))\n",
    "model.add(LeakyReLU(alpha=0.01))\n",
    "model.add(Dense(units=500))\n",
    "model.add(LeakyReLU(alpha=0.01))\n",
    "\n",
    "model.add(Dense(units=10, activation='softmax'))\n",
    "model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics=[\"acc\"],)\n",
    "model.summary()\n",
    "\n",
    "model.fit(X_train,y_train,epochs=50,batch_size=32,validation_data=(X_test,y_test))    \n",
    "pred=model.predict(X_test)\n",
    "print(accuracy_score(y_test,pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
